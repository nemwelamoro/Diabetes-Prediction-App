# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt


# Import and read dataset in csv file
diabetes_data = pd.read_csv("C:/Users/FBI/Downloads/Diabetes_Prediction_2018_2022.csv")

#pre processing
# Check for missing values
print(diabetes_data.isnull().sum())

# remove column1 with missing values
diabetes_data= diabetes_data.drop('Column1' , axis=1)

#data types stored
diabetes_data.dtypes
#all are int64

#the z-score method is used to identify data points that are more than a certain number of standard deviations away from the mean
# calculate the z-score for each column
z_scores = np.abs((diabetes_data - diabetes_data.mean()) / diabetes_data.std())

# set a threshold z-score
threshold = 3

# identify potential outliers
outliers = diabetes_data[(z_scores > threshold).any(axis=1)]

# show the outliers
print(outliers)

# remove the rows with outliers
diabetes_data = diabetes_data[(z_scores <= threshold).all(axis=1)]

#descriptive statistics our dataset
print(diabetes_data.describe())


# Split the data into independent (features) and dependent (target) variables
X = diabetes_data.drop('Diabetes_012', axis=1)
y = diabetes_data['Diabetes_012']

# Split the dataset at 80% for training and 20% for testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
